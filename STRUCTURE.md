# Expected Directory Structure

After setup and running the system, your project should look like this:

```
iitmcvproj/
â”‚
â”œâ”€â”€ ğŸ“„ Core Python Files
â”‚   â”œâ”€â”€ main.py                      # Main pipeline
â”‚   â”œâ”€â”€ vehicle.py                   # Vehicle tracking classes
â”‚   â”œâ”€â”€ fusion.py                    # Multi-camera fusion
â”‚   â”œâ”€â”€ analytics.py                 # Analytics and logging
â”‚   â”œâ”€â”€ calibration.py               # Calibration tool
â”‚   â”œâ”€â”€ train_model.py               # Training script
â”‚   â”œâ”€â”€ extract_frames.py            # Frame extraction
â”‚   â”œâ”€â”€ analyze_results.py           # Results analysis
â”‚   â””â”€â”€ setup.py                     # Setup utility
â”‚
â”œâ”€â”€ ğŸ“‹ Configuration Files
â”‚   â”œâ”€â”€ config.yaml                  # Main configuration
â”‚   â”œâ”€â”€ requirements.txt             # Python dependencies
â”‚   â””â”€â”€ .gitignore                   # Git ignore rules
â”‚
â”œâ”€â”€ ğŸ“š Documentation
â”‚   â”œâ”€â”€ README.md                    # Complete documentation
â”‚   â”œâ”€â”€ QUICKSTART.md               # Quick start guide
â”‚   â”œâ”€â”€ COMMANDS.md                 # Command reference
â”‚   â”œâ”€â”€ IMPLEMENTATION_SUMMARY.md   # Project summary
â”‚   â””â”€â”€ STRUCTURE.md                # This file
â”‚
â”œâ”€â”€ ğŸ“‚ data/
â”‚   â”‚
â”‚   â”œâ”€â”€ ğŸ¥ videos/                  # Input videos
â”‚   â”‚   â”œâ”€â”€ camera1.mp4             # Camera 1 footage
â”‚   â”‚   â”œâ”€â”€ camera2.mp4             # Camera 2 footage
â”‚   â”‚   â”œâ”€â”€ camera1_frame.jpg       # Extracted frame for calibration
â”‚   â”‚   â””â”€â”€ camera2_frame.jpg       # Extracted frame for calibration
â”‚   â”‚
â”‚   â”œâ”€â”€ ğŸ—ºï¸ maps/                    # Global reference maps
â”‚   â”‚   â””â”€â”€ global_map.jpg          # Google Earth screenshot
â”‚   â”‚
â”‚   â”œâ”€â”€ ğŸ“ calibration/             # Homography matrices
â”‚   â”‚   â”œâ”€â”€ camera1_H.npy           # Camera 1 homography
â”‚   â”‚   â”œâ”€â”€ camera1_H.txt           # Human-readable matrix
â”‚   â”‚   â”œâ”€â”€ camera2_H.npy           # Camera 2 homography
â”‚   â”‚   â””â”€â”€ camera2_H.txt           # Human-readable matrix
â”‚   â”‚
â”‚   â””â”€â”€ ğŸ“Š dataset/                 # Training dataset
â”‚       â”œâ”€â”€ raw_frames/             # Extracted frames for labeling
â”‚       â”‚   â”œâ”€â”€ frame_000000_t0.00s.jpg
â”‚       â”‚   â”œâ”€â”€ frame_000001_t1.00s.jpg
â”‚       â”‚   â””â”€â”€ ...
â”‚       â”‚
â”‚       â”œâ”€â”€ images/                 # Organized images
â”‚       â”‚   â”œâ”€â”€ train/              # Training images (70%)
â”‚       â”‚   â”‚   â”œâ”€â”€ img_001.jpg
â”‚       â”‚   â”‚   â””â”€â”€ ...
â”‚       â”‚   â”œâ”€â”€ val/                # Validation images (20%)
â”‚       â”‚   â”‚   â”œâ”€â”€ img_150.jpg
â”‚       â”‚   â”‚   â””â”€â”€ ...
â”‚       â”‚   â””â”€â”€ test/               # Test images (10%)
â”‚       â”‚       â”œâ”€â”€ img_180.jpg
â”‚       â”‚       â””â”€â”€ ...
â”‚       â”‚
â”‚       â”œâ”€â”€ labels/                 # YOLO format labels
â”‚       â”‚   â”œâ”€â”€ train/              # Training labels
â”‚       â”‚   â”‚   â”œâ”€â”€ img_001.txt
â”‚       â”‚   â”‚   â””â”€â”€ ...
â”‚       â”‚   â”œâ”€â”€ val/                # Validation labels
â”‚       â”‚   â”‚   â”œâ”€â”€ img_150.txt
â”‚       â”‚   â”‚   â””â”€â”€ ...
â”‚       â”‚   â””â”€â”€ test/               # Test labels
â”‚       â”‚       â”œâ”€â”€ img_180.txt
â”‚       â”‚       â””â”€â”€ ...
â”‚       â”‚
â”‚       â””â”€â”€ dataset.yaml            # Dataset configuration
â”‚
â”œâ”€â”€ ğŸ¤– models/                      # Trained models
â”‚   â””â”€â”€ best.pt                     # Your custom trained model
â”‚
â”œâ”€â”€ ğŸƒ runs/                        # Training runs
â”‚   â””â”€â”€ train/
â”‚       â””â”€â”€ drone_traffic/          # Training experiment
â”‚           â”œâ”€â”€ weights/
â”‚           â”‚   â”œâ”€â”€ best.pt         # Best model weights
â”‚           â”‚   â””â”€â”€ last.pt         # Last epoch weights
â”‚           â”œâ”€â”€ results.csv         # Training metrics
â”‚           â”œâ”€â”€ confusion_matrix.png
â”‚           â”œâ”€â”€ results.png
â”‚           â””â”€â”€ ...
â”‚
â”œâ”€â”€ ğŸ“¤ output/                      # System outputs
â”‚   â”œâ”€â”€ traffic_data.csv            # Vehicle tracking log
â”‚   â”œâ”€â”€ heatmap.png                 # Traffic heatmap
â”‚   â”œâ”€â”€ result.mp4                  # Visualization video
â”‚   â”‚
â”‚   â””â”€â”€ analysis/                   # Analysis reports
â”‚       â”œâ”€â”€ report.html             # HTML report
â”‚       â”œâ”€â”€ vehicle_summaries.csv   # Per-vehicle summary
â”‚       â”œâ”€â”€ vehicle_counts_over_time.png
â”‚       â”œâ”€â”€ class_distribution.png
â”‚       â”œâ”€â”€ trajectory_lengths.png
â”‚       â”œâ”€â”€ speed_distribution.png
â”‚       â”œâ”€â”€ camera_coverage.png
â”‚       â””â”€â”€ spatial_heatmap.png
â”‚
â”œâ”€â”€ ğŸ’¾ backups/                     # Backups (optional)
â”‚   â””â”€â”€ 20251127_143000/
â”‚       â”œâ”€â”€ traffic_data.csv
â”‚       â”œâ”€â”€ config.yaml
â”‚       â””â”€â”€ ...
â”‚
â””â”€â”€ ğŸ venv/                        # Virtual environment
    â”œâ”€â”€ Scripts/
    â”œâ”€â”€ Lib/
    â””â”€â”€ ...
```

---

## File Descriptions

### Core Files

| File | Purpose | Size | Type |
|------|---------|------|------|
| `main.py` | Main pipeline orchestration | ~15 KB | Python |
| `vehicle.py` | Vehicle tracking system | ~12 KB | Python |
| `fusion.py` | Multi-camera fusion logic | ~15 KB | Python |
| `analytics.py` | Analytics and logging | ~16 KB | Python |
| `calibration.py` | Camera calibration tool | ~12 KB | Python |
| `train_model.py` | Model training pipeline | ~14 KB | Python |
| `extract_frames.py` | Frame extraction utility | ~8 KB | Python |
| `analyze_results.py` | Results analysis | ~14 KB | Python |

### Data Files

| File | Purpose | Format | Typical Size |
|------|---------|--------|--------------|
| `camera1.mp4` | Camera 1 video feed | Video | 100 MB - 1 GB |
| `global_map.jpg` | Reference map | Image | 500 KB - 5 MB |
| `camera1_H.npy` | Homography matrix | NumPy | 144 bytes |
| `best.pt` | Trained model | PyTorch | 6-50 MB |
| `traffic_data.csv` | Tracking log | CSV | 1-100 MB |

### Label Format (YOLO)

Each `.txt` file contains bounding boxes:
```
class_id center_x center_y width height
0 0.5234 0.3456 0.1234 0.0987
1 0.7123 0.6543 0.0876 0.0654
```

Where:
- `class_id`: 0=Car, 1=Bike, 2=Pedestrian
- Coordinates normalized (0-1)

### CSV Output Format

`traffic_data.csv`:
```csv
timestamp,frame,vehicle_id,class,global_x,global_y,camera_id,confidence,total_distance,average_speed,trajectory_length
2025-11-27 10:30:15.123,1,1,Car,450.2,320.5,1,0.87,0.0,0.0,1
2025-11-27 10:30:15.156,2,1,Car,451.8,322.1,1,0.89,2.3,2.3,2
```

---

## Storage Requirements

### Minimum Setup
- Python files: ~500 KB
- Dependencies (venv): ~2 GB
- Total: ~2.5 GB

### With Training Data
- Dataset (200 images): ~50 MB
- Labels: ~1 MB
- Total: ~2.5 GB

### Full Project
- Videos (2 cameras, 10 min): ~2 GB
- Dataset: ~50 MB
- Training runs: ~100 MB
- Models: ~50 MB
- Output: ~100 MB
- **Total: ~5 GB**

### Long-term Storage
For 1 hour of multi-camera footage:
- Input videos: ~12 GB
- Output video: ~1 GB
- CSV logs: ~50 MB
- **Total: ~13 GB**

---

## File Lifecycle

### Training Phase
```
Raw Videos â†’ Frames â†’ Labeled Data â†’ Dataset â†’ Trained Model
```

### Calibration Phase
```
Video Frame + Map â†’ Point Selection â†’ Homography Matrix
```

### Processing Phase
```
Videos + Model + Homography â†’ Detection â†’ Fusion â†’ Output
```

### Analysis Phase
```
CSV Log â†’ Analysis Script â†’ Reports + Visualizations
```

---

## Important Files to Backup

### Essential (Cannot Regenerate)
1. âœ… Labeled dataset (`data/dataset/`)
2. âœ… Trained model (`models/best.pt`)
3. âœ… Homography matrices (`data/calibration/`)
4. âœ… Configuration (`config.yaml`)

### Important (Time-consuming to Regenerate)
5. Raw videos (`data/videos/`)
6. Global map (`data/maps/global_map.jpg`)
7. Training runs (`runs/train/`)

### Can Regenerate
- Output files (`output/`)
- Virtual environment (`venv/`)
- Temporary files

---

## Gitignore Recommendations

Files to exclude from version control:

```gitignore
# Data
data/videos/*.mp4
data/videos/*.avi
data/dataset/raw_frames/
data/dataset/images/
data/dataset/labels/

# Models
models/*.pt
runs/

# Output
output/
*.csv

# Environment
venv/
__pycache__/
*.pyc
```

Files to include:
- Source code (`.py`)
- Configuration (`.yaml`)
- Documentation (`.md`)
- Requirements (`requirements.txt`)
- Sample homography matrices (optional)

---

## Cleanup Commands

### Clean Output Files
```powershell
Remove-Item -Recurse -Force "output\*"
```

### Clean Training Runs
```powershell
Remove-Item -Recurse -Force "runs\*"
```

### Deep Clean (Keep Source Only)
```powershell
Remove-Item -Recurse -Force "venv", "output", "runs", "data\dataset\raw_frames"
```

### Fresh Start
```powershell
# Keep only source code and configs
Remove-Item -Recurse -Force "venv", "output", "runs", "data", "models"
python setup.py
```

---

## Validation Checklist

Before running the system, ensure these exist:

### Required Files
- [ ] `config.yaml` (configured with your paths)
- [ ] `data/videos/camera1.mp4` (or your video files)
- [ ] `data/maps/global_map.jpg` (your reference map)
- [ ] `data/calibration/camera1_H.npy` (calibrated)
- [ ] `models/best.pt` (trained model)

### Required Directories
- [ ] `data/videos/`
- [ ] `data/maps/`
- [ ] `data/calibration/`
- [ ] `models/`
- [ ] `output/`

### Optional but Recommended
- [ ] `data/dataset/` (if training)
- [ ] `runs/train/` (training history)
- [ ] `backups/` (backup important files)

---

## Quick Setup Commands

### Create All Directories
```powershell
python setup.py
```

### Manual Creation
```powershell
$dirs = @(
    "data\videos",
    "data\maps",
    "data\calibration",
    "data\dataset\raw_frames",
    "data\dataset\images\train",
    "data\dataset\images\val",
    "data\dataset\images\test",
    "data\dataset\labels\train",
    "data\dataset\labels\val",
    "data\dataset\labels\test",
    "models",
    "output",
    "runs\train"
)

foreach ($dir in $dirs) {
    New-Item -ItemType Directory -Force -Path $dir
}
```

---

## Size Management Tips

### Reduce Dataset Size
- Use fewer frames (100-150 is usually sufficient)
- Compress videos before storing
- Delete raw frames after labeling

### Reduce Model Size
- Use YOLOv8n (nano) instead of larger variants
- Export to ONNX for deployment

### Reduce Output Size
- Lower output video resolution
- Compress output videos
- Archive old results

---

This structure follows best practices for machine learning projects and maintains separation of concerns between code, data, models, and outputs.
